{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rakeshkumar/miniconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas import Series as s , DataFrame as df\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "import seaborn as sb\n",
    "from matplotlib import pyplot as plt, rcParams as rc\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "rc[\"figure.figsize\"] = 10,6\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step : 1) Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1) Load Data\n",
    "data = pd.read_csv(\"hp_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step : 2) Read and Analysis Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataAllDetails(data):\n",
    "    print(\"Return a tuple representing the dimensionality of the DF.  :   \",data.shape)\n",
    "    print(\"Count of Each Data                                          :  \",data.count())\n",
    "    print(\"Start,End,Column,Step                                       :  \",data.axes)\n",
    "    print(\"Column                                                      :  \",data.columns)\n",
    "    print(\"First 5 items                                               :  \",data.head(2))\n",
    "    print(\"Missing Vlaue                                               :  \",data.isnull().sum())\n",
    "    print(\"information                                                 :  \",data.info())\n",
    "    print(\"Description                                                 :  \",data.describe())\n",
    "    print(\"Size(Row*Column) represent the no of elements in this object:  \",data.size)\n",
    "    print(\"Return unbiased skew over requested axis                    :  \",data.skew())\n",
    "    print(\"std err of mean                                             :  \",data.sem())\n",
    "    print(\"Return sample standard deviation over requested axis        :  \",data.std())\n",
    "    print(\"sum of every data                                           :  \",data.sum())\n",
    "    print(\"Copy Data to other                                          :  \",data.copy())\n",
    "    print(\"Correlation of Data                                         :  \",data.corr())\n",
    "    print(\"Covariance of Columns                                       :  \",data.cov())\n",
    "    print(\"cumulative sum over data                                    :  \",data.cumsum())\n",
    "    print(\"cumulative min or max                                       :  \",data.cummin())\n",
    "    print(\"Remove duplicate row                                        :  \",data.drop_duplicates())\n",
    "    print(\"Romove missing Value                                        :  \",data.dropna())\n",
    "    print(\"Drop Specify Label                                          :  \",data.drop(labels=[2,49,78,88]))\n",
    "    print(\"Drop Specify Label(Plz check inplace true means)            :  \",data.drop(labels=[2,49,78,88],inplace=True))\n",
    "    print(\"Tell about Data Types                                       :  \",data.dtypes)\n",
    "    print(\"Find the Duplicate Row                                      :  \",data.duplicated())\n",
    "    print(\"DataFrame is Empty(True) or not(False)                      :  \",data.empty)\n",
    "    print(\"Expanding                                                   :  \",data.expanding())\n",
    "    print(\"Fill Na/Nan Value using Specify metho                       :  \",data.fillna)\n",
    "    #print(\"rows/columns of DF A/c to labels in specified index   :  \",data.filter)\n",
    "    #print(\" check it(fill backward)          :  \",data.bfill())\n",
    "    #print(\" check it(fill forward)         :  \",data.ffill())\n",
    "    #print(\"    check it ?      :  \",data.from_csv)\n",
    "    #print(\"       check it ?   :  \",data.from_dict,data.from_items,data.from_records)\n",
    "    print(\"Return(indication of sparse/dense and dtype) in Df          :  \",data.from_records)\n",
    "    print(\"Tell about Data Types(check abobe ftypes)                   :  \",data.dtypes)\n",
    "    print(\"Return counts of unique dtypes in this object               :  \",data.get_dtype_counts())\n",
    "    print(\"Return counts of unique dtypes in this object(dense)        :  \",data.get_ftype_counts())\n",
    "    print(\"Return ndarray after convert sparse values to dense         :  \",data.get_values())\n",
    "    #print(\"   check it       :  \",data.groupby)\n",
    "    print(\"RangeIndex(start=0,stop=data size, step=1)                  :  \",data.index)\n",
    "    print(\"concise summary of DF,Dtypes,Memory,Shape,Many Info         :  \",data.info)\n",
    "    #print(\"    check it      :  \",data.insert)\n",
    "    #print(\"  check it        :  \",data.interpolate)\n",
    "    #print(\"   check it       :  \",data.is_copy)\n",
    "    print(\"Detect the Missing Value(Both Same isna & isnull )           :  \",data.isna().sum(),data.isnull().sum())\n",
    "    #print(\"    check it      :  \",data.join)\n",
    "    print(\"Get the 'info axis(same as columns : data.columns)           :  \",data.keys,data.columns)\n",
    "    print(\"unbiased kurt over requested axis using Fisher's def         :  \",data.kurt,data.kurtosis)\n",
    "    print(\"both are same data.kurt & data.kurtosis                      :  \",data.kurt,data.kurtosis)\n",
    "    print(\"Return index for last non-NA/null value                      :  \",data.last_valid_index())\n",
    "    print(\"mean absolute deviation value for the requested axis         :  \",data.mad())\n",
    "    print(\"Returns the maximum of the values in the object              :  \",data.max())\n",
    "    print(\"Returns the minimum of the values in the object              :  \",data.min())\n",
    "    print(\"Return the mean of the values for the requested axis         :  \",data.mean())\n",
    "    print(\"Return the median of the values for the request axis         :  \",data.median())\n",
    "    #print(\"   check it       :  \",data.melt())\n",
    "    print(\"Return the memory usage of each column in bytes.             :  \",data.memory_usage())\n",
    "    #print(\"  check it        :  \",data.merge)\n",
    "    #print(\"    check it (mod, mul,multiply)      :  \",data,mod,data.mul,data.multiply)\n",
    "    print(\"Return an int representing the no of axes/array dims         :  \",data.ndim)\n",
    "    print(\"row's DF sorted by the n smallest values of `columns         :  \",data.nsmallest(n=10,columns=\"price\"))\n",
    "    print(\"row's DF sorted by the n largest values of `columns          :  \",data.nlargest(n=10,columns=\"price\"))\n",
    "    print(\"Find existing(non-missing) values(Same:notna,notnull)        :  \",data.notna(),data.notnull())\n",
    "    print(\"Series with no of distinct observations over requested axis  :  \",data.nunique(axis=0))\n",
    "    #print(\"     check it     :  \",data.pct_change)\n",
    "    #print(\" check it(pivot,pivot_table)         :  \",data.pivot,data.pivot_table)\n",
    "    print(\"Return item & drop/delete from frame.Raise Error,if not found:  \",data.pop(\"price\"))\n",
    "    #print(\"  check it        :  \",data.pow)\n",
    "    print(\"product/prod same of the value for the request(default axis=0):  \",data.prod(axis=0),data.product(axis=0))\n",
    "    print(\"values quantile over requested axis, a la numpy.percentile.   :  \",data.quantile())\n",
    "    #print(\"    check it      :  \",data.query)\n",
    "    #print(\"       check it   :  \",data.radd)\n",
    "    print(\"Compute numerical data rank(1 through n)along axis.Equal values:  \",data.rank(numeric_only=True,axis=0))\n",
    "    print(\"Conform DF to new index with optional filling logic,placing    :  \",data.reindex().sum())\n",
    "    #print(\"check it  :  \",data.rename,data.rename_axis,data.reorder_levels,data.replace,data.resample,data.resample)\n",
    "    #print(\"   check it :  \",data.reset_index(),data.rmod,data.rmul,data.rolling,data.rpow,data.rsub,data.rtruediv)\n",
    "    print(\"Round a DataFrame to a variable number of decimal places.      :  \",data.round())\n",
    "    print(\"Return a random sample of items from an axis of object.        :  \",data.sample())\n",
    "    print(\"check it      :  \",data.select,data.set_index,data.set_value)\n",
    "    print(\"Return unbiased standard error of the mean over requested axis.:  \",data.sem())\n",
    "    print(\"Shift index by desired no of periods with an optional time freq:  \",data.shift(axis=0,periods=3))\n",
    "    print(\"Equivalent to `shift` without copying data                     :  \",data.slice_shift(axis=0,periods=5))\n",
    "    print(\"Sort object by labels (along an axis=0, default)               :  \",data.sort_index(axis=1,ascending=False))\n",
    "    print(\"Sort by the values along either axis                           :  \",data.sort_values(by=[\"price\",\"yearsOld\"],axis=0,ascending=False))\n",
    "    print(\"Sort multilevel index by chosen axis level(sort based on words):  \",data.sortlevel(level=0, axis=1, ascending=True))\n",
    "    #print(\"Check it  :  \",data.stack(),data.sub,data.subtract())\n",
    "    print(\"Display All Items(same as head(total no of items))             :  \",data.style)\n",
    "    print(\"Interchange axes & swap values axes(swap rows to columns)      :  \",data.swapaxes(axis1=0,axis2=1,copy=False))\n",
    "    print(\"Interchange axes & swap values axes appropriately              :  \",data.swaplevel(i=0,j=0,axis=0))\n",
    "    #print(\" check it    :  \",data.unstack,data.update())\n",
    "    print(\"Return unbiased variance over requested axis.                  :  \",data.var(axis=0))\n",
    "    #print(\"   check it       :  \",data.where,data.xs())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rename Column Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dic = { \"KEY\" : \"VALUE\"}\n",
    "def renameColumn(dic, data ) :\n",
    "    # DICTIONARY : KEY AND VALUE , KEY IS OLD COLUMN NAME , VALUE IS NEW COLUMN NAME\n",
    "    data = data.rename(columns=dic)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step : 3) Visualization the Data\n",
    "There are 2 types of library to visualization.\n",
    "##1) Matplot 2) Seaborn(use attractive and looking good and more features)\n",
    "#Draw the Graph (Histogram, Straight Line, Pie, Bar, Scatter, ETC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graphDetail():\n",
    "    print(\"Prints the values to a stream, or to sys.stdout by default boxplot      :  \",data.boxplot())\n",
    "    print(\"Prints the values to a stream, or to sys.stdout by default hist         :  \",data.hist())\n",
    "    print(\"Prints the values to a stream, or to sys.stdout by default plot         :  \",data.plot())\n",
    "    #print(\"Prints the values to a stream, or to sys.stdout by default              :  \",data.boxplot())\n",
    "    #print(\"Prints the values to a stream, or to sys.stdout by default              :  \",data.boxplot())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step : 4) Data Preprocessing\n",
    "used to convert the raw data into a clean data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A) Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getDataAllDetails(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.head(3) # before label encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B) Label Encoding : Convert Categorical Value to Integer Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1st Method \n",
    "# char_cols = data.dtypes.pipe(lambda x: x[x == 'object']).index\n",
    "# for c in char_cols:\n",
    "#     data[c] = pd.factorize(data[c])[0]\n",
    "    \n",
    "#OR 2nd method\n",
    "# enc = LabelEncoder()\n",
    "# data[\"place\"] = enc.fit_transform(data[\"place\"])\n",
    "# data[\"sale\"] = enc.fit_transform(data[\"sale\"])\n",
    "# data[\"built\"] = enc.fit_transform(data[\"built\"])\n",
    "\n",
    "#Do not try to change integer value\n",
    "#data[\"price\"] = enc.fit_transform(data[\"price\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Encoding  and Inverse: Convert Categorical Value to Integer Value and Vice-versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder \n",
    "def labelEncodingCategoryToIntergerViceVersa(dataset):\n",
    "    '''\n",
    "    @author Rakesh\n",
    "    @see The function label encodes the object type columns and gives label      encoded and inverse tranform of the label encoded data\n",
    "    @param dataset dataframe on whoes column the label encoding has to be done\n",
    "    @return label encoded and inverse tranform of the label encoded data.\n",
    "   ''' \n",
    "    data_original = dataset[:]\n",
    "    data_tranformed = dataset[:]\n",
    "    for y in dataset.columns:\n",
    "       #check the dtype of the column object type contains strings or chars\n",
    "        if (dataset[y].dtype == object):\n",
    "            print(\"The string type features are  : \" + y)\n",
    "            le = LabelEncoder()\n",
    "            le.fit(dataset[y].unique())\n",
    "            #label encoded data\n",
    "            data_tranformed[y] = le.transform(dataset[y])\n",
    "            #inverse label transform  data\n",
    "            data_original[y] = le.inverse_transform(data_tranformed[y])\n",
    "    return data_tranformed,data_original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rename Column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dic = { \"place\" : \"Places\", \"built\" : \"builts\"}\n",
    "dic = { \"Unnamed: 0\" : \"ID\"}\n",
    "data = renameColumn(dic,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The string type features are  : place\n",
      "The string type features are  : built\n",
      "The string type features are  : sale\n"
     ]
    }
   ],
   "source": [
    "data_tranformed,data_original = labelEncodingCategoryToIntergerViceVersa(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>price</th>\n",
       "      <th>place</th>\n",
       "      <th>built</th>\n",
       "      <th>sqft</th>\n",
       "      <th>sale</th>\n",
       "      <th>yearsOld</th>\n",
       "      <th>floor</th>\n",
       "      <th>totalFloor</th>\n",
       "      <th>bhk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1341</td>\n",
       "      <td>6300000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1450</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2126</td>\n",
       "      <td>11500000</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>2190</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>816</td>\n",
       "      <td>3800000</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1019</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID     price  place  built  sqft  sale  yearsOld  floor  totalFloor  bhk\n",
       "0  1341   6300000      2      1  1450     0         5      1           4    1\n",
       "1  2126  11500000     14      1  2190     0         5      3           5    3\n",
       "2   816   3800000     12      1  1019     0         1      2           5    2"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tranformed.head(3)# after label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>price</th>\n",
       "      <th>place</th>\n",
       "      <th>built</th>\n",
       "      <th>sqft</th>\n",
       "      <th>sale</th>\n",
       "      <th>yearsOld</th>\n",
       "      <th>floor</th>\n",
       "      <th>totalFloor</th>\n",
       "      <th>bhk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1341</td>\n",
       "      <td>6300000</td>\n",
       "      <td>BTM Layout</td>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>1450</td>\n",
       "      <td>Resale</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2126</td>\n",
       "      <td>11500000</td>\n",
       "      <td>Yelahanka</td>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>2190</td>\n",
       "      <td>Resale</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>816</td>\n",
       "      <td>3800000</td>\n",
       "      <td>Whitefield</td>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>1019</td>\n",
       "      <td>Resale</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID     price       place                 built  sqft    sale  yearsOld  \\\n",
       "0  1341   6300000  BTM Layout  Super built-up  Area  1450  Resale         5   \n",
       "1  2126  11500000   Yelahanka  Super built-up  Area  2190  Resale         5   \n",
       "2   816   3800000  Whitefield  Super built-up  Area  1019  Resale         1   \n",
       "\n",
       "   floor  totalFloor  bhk  \n",
       "0      1           4    1  \n",
       "1      3           5    3  \n",
       "2      2           5    2  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_original.head(3)# original data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_tranformed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-884abc872b3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# feature engineering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_tranformed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ID\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"place\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"built\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"sqft\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"sale\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"yearsOld\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"floor\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"totalFloor\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"bhk\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_tranformed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_tranformed' is not defined"
     ]
    }
   ],
   "source": [
    "# feature engineering\n",
    "x = data_tranformed.loc[:,[\"ID\",\"place\",\"built\",\"sqft\",\"sale\",\"yearsOld\",\"floor\",\"totalFloor\",\"bhk\"]]\n",
    "y = data_tranformed.price\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Split Dataset (x_train, x_test , y_train , y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test , y_train , y_test = train_test_split(x ,y , test_size = 0.25 , random_state = 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7)Select Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"Linear Regression\", \"Decision Tree Regression\", \"Random Forest Regression\"]\n",
    "\n",
    "algorithms = [ LinearRegression(), DecisionTreeRegressor(), RandomForestRegressor()]\n",
    "\n",
    "columns_name = [\"Model_name\", \"Random_state\",'r2_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8)Fit Model and Predict Model and Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows=[]\n",
    "def addRandomStateForAlgorithm(x,y,names,algorithms,columns_name,random_state_list):    \n",
    "    for j in range(len(algorithms)):\n",
    "        model = algorithms[j]\n",
    "        for i in random_state_list:\n",
    "            x_train, x_test , y_train , y_test = train_test_split(x ,y , test_size = 0.25 , random_state = i)\n",
    "            model.fit(x_train,y_train)\n",
    "            pred_testa = model.predict(x_test)\n",
    "            row = [names[j],i,r2_score (y_test,pred_test)]\n",
    "            rows.append(row)\n",
    "    models_df = pd.DataFrame(rows)   \n",
    "    models_df.columns = columns_name\n",
    "    print(models_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state_list_up_to_10 = [0,1,2,3,4,5,6,7,8,9,10]\n",
    "random_state_list_10_up_to_20 = [10,11,12,13,14,15,16,17,18,19,20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Model_name  Random_state  r2_score\n",
      "0          Linear Regression             0  0.864431\n",
      "1          Linear Regression             1  0.841275\n",
      "2          Linear Regression             2  0.842930\n",
      "3          Linear Regression             3  0.875680\n",
      "4          Linear Regression             4  0.819867\n",
      "5          Linear Regression             5  0.865792\n",
      "6          Linear Regression             6  0.845014\n",
      "7          Linear Regression             7  0.865988\n",
      "8          Linear Regression             8  0.859320\n",
      "9          Linear Regression             9  0.845247\n",
      "10         Linear Regression            10  0.881476\n",
      "11  Decision Tree Regression             0  1.000000\n",
      "12  Decision Tree Regression             1  1.000000\n",
      "13  Decision Tree Regression             2  1.000000\n",
      "14  Decision Tree Regression             3  1.000000\n",
      "15  Decision Tree Regression             4  1.000000\n",
      "16  Decision Tree Regression             5  1.000000\n",
      "17  Decision Tree Regression             6  1.000000\n",
      "18  Decision Tree Regression             7  0.998633\n",
      "19  Decision Tree Regression             8  1.000000\n",
      "20  Decision Tree Regression             9  1.000000\n",
      "21  Decision Tree Regression            10  1.000000\n",
      "22  Random Forest Regression             0  1.000000\n",
      "23  Random Forest Regression             1  0.999953\n",
      "24  Random Forest Regression             2  0.999983\n",
      "25  Random Forest Regression             3  0.999996\n",
      "26  Random Forest Regression             4  1.000000\n",
      "27  Random Forest Regression             5  1.000000\n",
      "28  Random Forest Regression             6  1.000000\n",
      "29  Random Forest Regression             7  0.999945\n",
      "30  Random Forest Regression             8  1.000000\n",
      "31  Random Forest Regression             9  1.000000\n",
      "32  Random Forest Regression            10  1.000000\n"
     ]
    }
   ],
   "source": [
    "addRandomStateForAlgorithm(x, y,names,algorithms,columns_name,random_state_list_up_to_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[2:]\n",
    "#data[:3]\n",
    "#data.iloc[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(\"payment-fraud-inference.csv\")\n",
    "data2 = pd.read_csv(\"payment-fraud-train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 17)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 18)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 17 columns):\n",
      "id                       50000 non-null int64\n",
      "device                   50000 non-null object\n",
      "os                       50000 non-null object\n",
      "channel                  50000 non-null object\n",
      "vertical                 50000 non-null object\n",
      "cust_past_txn_hour_01    50000 non-null int64\n",
      "dom_travel               50000 non-null int64\n",
      "intl_travel              50000 non-null int64\n",
      "ip_match                 50000 non-null object\n",
      "latency_time             50000 non-null float64\n",
      "avg_amt_vertical         50000 non-null int64\n",
      "max_amt_vertical         50000 non-null int64\n",
      "email_domain             50000 non-null object\n",
      "avg_amt_6m               50000 non-null float64\n",
      "avg_amt_1m               50000 non-null float64\n",
      "ip3_fraud_rate           50000 non-null float64\n",
      "amount                   50000 non-null float64\n",
      "dtypes: float64(5), int64(6), object(6)\n",
      "memory usage: 6.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 18 columns):\n",
      "id                       100000 non-null int64\n",
      "device                   100000 non-null object\n",
      "os                       100000 non-null object\n",
      "channel                  100000 non-null object\n",
      "vertical                 100000 non-null object\n",
      "cust_past_txn_hour_01    100000 non-null int64\n",
      "dom_travel               100000 non-null int64\n",
      "intl_travel              100000 non-null int64\n",
      "ip_match                 100000 non-null object\n",
      "latency_time             100000 non-null float64\n",
      "avg_amt_vertical         100000 non-null int64\n",
      "max_amt_vertical         100000 non-null int64\n",
      "email_domain             100000 non-null object\n",
      "avg_amt_6m               100000 non-null float64\n",
      "avg_amt_1m               100000 non-null float64\n",
      "ip3_fraud_rate           100000 non-null float64\n",
      "amount                   100000 non-null float64\n",
      "fraud                    100000 non-null int64\n",
      "dtypes: float64(5), int64(7), object(6)\n",
      "memory usage: 13.7+ MB\n"
     ]
    }
   ],
   "source": [
    "data2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>device</th>\n",
       "      <th>os</th>\n",
       "      <th>channel</th>\n",
       "      <th>vertical</th>\n",
       "      <th>cust_past_txn_hour_01</th>\n",
       "      <th>dom_travel</th>\n",
       "      <th>intl_travel</th>\n",
       "      <th>ip_match</th>\n",
       "      <th>latency_time</th>\n",
       "      <th>avg_amt_vertical</th>\n",
       "      <th>max_amt_vertical</th>\n",
       "      <th>email_domain</th>\n",
       "      <th>avg_amt_6m</th>\n",
       "      <th>avg_amt_1m</th>\n",
       "      <th>ip3_fraud_rate</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>pc</td>\n",
       "      <td>mac-os</td>\n",
       "      <td>pc-browser</td>\n",
       "      <td>auto-car</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>same-city</td>\n",
       "      <td>8.192592</td>\n",
       "      <td>800</td>\n",
       "      <td>10000</td>\n",
       "      <td>com</td>\n",
       "      <td>5932.212448</td>\n",
       "      <td>5183.262111</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1549.572084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>pc</td>\n",
       "      <td>windows-vista</td>\n",
       "      <td>pc-browser</td>\n",
       "      <td>food-grocery</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>diff-country</td>\n",
       "      <td>70.086750</td>\n",
       "      <td>300</td>\n",
       "      <td>4000</td>\n",
       "      <td>com</td>\n",
       "      <td>5516.563929</td>\n",
       "      <td>10317.137310</td>\n",
       "      <td>0.00</td>\n",
       "      <td>649.181672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id device             os     channel      vertical  cust_past_txn_hour_01  \\\n",
       "0   1     pc         mac-os  pc-browser      auto-car                      1   \n",
       "1   2     pc  windows-vista  pc-browser  food-grocery                      0   \n",
       "\n",
       "   dom_travel  intl_travel      ip_match  latency_time  avg_amt_vertical  \\\n",
       "0           0            0     same-city      8.192592               800   \n",
       "1           3            0  diff-country     70.086750               300   \n",
       "\n",
       "   max_amt_vertical email_domain   avg_amt_6m    avg_amt_1m  ip3_fraud_rate  \\\n",
       "0             10000          com  5932.212448   5183.262111            0.05   \n",
       "1              4000          com  5516.563929  10317.137310            0.00   \n",
       "\n",
       "        amount  \n",
       "0  1549.572084  \n",
       "1   649.181672  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>device</th>\n",
       "      <th>os</th>\n",
       "      <th>channel</th>\n",
       "      <th>vertical</th>\n",
       "      <th>cust_past_txn_hour_01</th>\n",
       "      <th>dom_travel</th>\n",
       "      <th>intl_travel</th>\n",
       "      <th>ip_match</th>\n",
       "      <th>latency_time</th>\n",
       "      <th>avg_amt_vertical</th>\n",
       "      <th>max_amt_vertical</th>\n",
       "      <th>email_domain</th>\n",
       "      <th>avg_amt_6m</th>\n",
       "      <th>avg_amt_1m</th>\n",
       "      <th>ip3_fraud_rate</th>\n",
       "      <th>amount</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>pc</td>\n",
       "      <td>ms-dos</td>\n",
       "      <td>pc-browser</td>\n",
       "      <td>food-grocery</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>same-city</td>\n",
       "      <td>17.178203</td>\n",
       "      <td>300</td>\n",
       "      <td>4000</td>\n",
       "      <td>com</td>\n",
       "      <td>1822.552062</td>\n",
       "      <td>3496.805665</td>\n",
       "      <td>0.05</td>\n",
       "      <td>132.193108</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>mobile</td>\n",
       "      <td>android</td>\n",
       "      <td>app-based</td>\n",
       "      <td>fashion-clothing</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>same-state</td>\n",
       "      <td>83.642966</td>\n",
       "      <td>800</td>\n",
       "      <td>6000</td>\n",
       "      <td>com</td>\n",
       "      <td>1659.337804</td>\n",
       "      <td>3617.543556</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2591.748978</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  device       os     channel          vertical  cust_past_txn_hour_01  \\\n",
       "0   1      pc   ms-dos  pc-browser      food-grocery                      0   \n",
       "1   2  mobile  android   app-based  fashion-clothing                      1   \n",
       "\n",
       "   dom_travel  intl_travel    ip_match  latency_time  avg_amt_vertical  \\\n",
       "0           0            0   same-city     17.178203               300   \n",
       "1           1            0  same-state     83.642966               800   \n",
       "\n",
       "   max_amt_vertical email_domain   avg_amt_6m   avg_amt_1m  ip3_fraud_rate  \\\n",
       "0              4000          com  1822.552062  3496.805665            0.05   \n",
       "1              6000          com  1659.337804  3617.543556            0.00   \n",
       "\n",
       "        amount  fraud  \n",
       "0   132.193108      0  \n",
       "1  2591.748978      0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = data1  + data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 18)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 100000 entries, 0 to 99999\n",
      "Data columns (total 18 columns):\n",
      "amount                   50000 non-null float64\n",
      "avg_amt_1m               50000 non-null float64\n",
      "avg_amt_6m               50000 non-null float64\n",
      "avg_amt_vertical         50000 non-null float64\n",
      "channel                  50000 non-null object\n",
      "cust_past_txn_hour_01    50000 non-null float64\n",
      "device                   50000 non-null object\n",
      "dom_travel               50000 non-null float64\n",
      "email_domain             50000 non-null object\n",
      "fraud                    0 non-null float64\n",
      "id                       50000 non-null float64\n",
      "intl_travel              50000 non-null float64\n",
      "ip3_fraud_rate           50000 non-null float64\n",
      "ip_match                 50000 non-null object\n",
      "latency_time             50000 non-null float64\n",
      "max_amt_vertical         50000 non-null float64\n",
      "os                       50000 non-null object\n",
      "vertical                 50000 non-null object\n",
      "dtypes: float64(12), object(6)\n",
      "memory usage: 14.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
